{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyTorch_Neural_Network.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"kuUIFqs4JptO","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"peI8558uBPX2","colab_type":"code","colab":{}},"source":["# Define the network\n","\n","class Net(nn.Module):\n","  \n","  def __init__(self):\n","    super(Net, self).__init__()\n","    \n","    self.conv1 = nn.Conv2d(1, 6, 3) # 1 input image channel, 6 output channels, 3x3 square convolution kernel\n","    self.conv2 = nn.Conv2d(6, 16, 3)\n","    \n","    self.fc1 = nn.Linear(16*6*6, 120) # 6*6 from image dimension\n","    self.fc2 = nn.Linear(120, 84)\n","    self.fc3 = nn.Linear(84, 10)\n","    \n","    \n","  def forward(self, x):\n","    # Max pooling over a (2,2) window\n","    x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n","    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","    x = x.view(-1, self.num_flat_features(x)) # view function is used to reshape a tensor\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.fc3(x)\n","    return x\n","  \n","  def num_flat_features(self, x):\n","    size = x.size()[1:] # all dimensions except the batch dimension\n","    num_features = 1\n","    for s in size:\n","      num_features *= s\n","    return num_features    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xcUFvhCNJulC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"58c3ab1a-b611-4cd5-cd30-fb0abcc3096d","executionInfo":{"status":"ok","timestamp":1565602251076,"user_tz":-330,"elapsed":659,"user":{"displayName":"SANKET RAI","photoUrl":"https://lh3.googleusercontent.com/-1z7oHX9PeDQ/AAAAAAAAAAI/AAAAAAAAAZA/oAjIoG_UNyM/s64/photo.jpg","userId":"16202345156323134081"}}},"source":["net = Net()\n","print(net)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Net(\n","  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n","  (fc1): Linear(in_features=576, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=84, bias=True)\n","  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g8pJIMQp6bk6","colab_type":"code","colab":{}},"source":["# the backward function is automatically defined using autograd()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"th4h5Un1Jjwq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"612d5bb9-0ef9-4e78-bbfe-fd8aac8f1eab","executionInfo":{"status":"ok","timestamp":1565602253628,"user_tz":-330,"elapsed":643,"user":{"displayName":"SANKET RAI","photoUrl":"https://lh3.googleusercontent.com/-1z7oHX9PeDQ/AAAAAAAAAAI/AAAAAAAAAZA/oAjIoG_UNyM/s64/photo.jpg","userId":"16202345156323134081"}}},"source":["net.parameters() # retuns the learnable parameters"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<generator object Module.parameters at 0x7f10b62ceca8>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"3mKgIgeaJ8we","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"e2e92bb4-38b2-4cd4-8822-d51dde705839","executionInfo":{"status":"ok","timestamp":1565602254903,"user_tz":-330,"elapsed":739,"user":{"displayName":"SANKET RAI","photoUrl":"https://lh3.googleusercontent.com/-1z7oHX9PeDQ/AAAAAAAAAAI/AAAAAAAAAZA/oAjIoG_UNyM/s64/photo.jpg","userId":"16202345156323134081"}}},"source":["params = list(net.parameters())\n","print(len(params))\n","print(params[0].size()) # weights of conv1"],"execution_count":19,"outputs":[{"output_type":"stream","text":["10\n","torch.Size([6, 1, 3, 3])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ppsg7BHdKMMZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"56153108-55bf-4066-8493-73eaadc60e59","executionInfo":{"status":"ok","timestamp":1565602774240,"user_tz":-330,"elapsed":979,"user":{"displayName":"SANKET RAI","photoUrl":"https://lh3.googleusercontent.com/-1z7oHX9PeDQ/AAAAAAAAAAI/AAAAAAAAAZA/oAjIoG_UNyM/s64/photo.jpg","userId":"16202345156323134081"}}},"source":["# the input size for the NN  is 32x32\n","\n","input = torch.randn(1, 1, 32, 32) # torch.nn does not support single samples, but only minibatches of one or more samples\n","out = net(input)\n","print(out)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["tensor([[-0.0230,  0.0344,  0.0374,  0.0749,  0.0750, -0.1744,  0.0148, -0.1050,\n","         -0.0839, -0.1194]], grad_fn=<AddmmBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d9g3p0e-KiIO","colab_type":"code","colab":{}},"source":["# backpropagation with random gradients\n","\n","out.backward(torch.randn(1, 10))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-FSlQn25Mjm5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3ad13519-7b6d-4095-8312-c0285f0054d9","executionInfo":{"status":"ok","timestamp":1565602913907,"user_tz":-330,"elapsed":1078,"user":{"displayName":"SANKET RAI","photoUrl":"https://lh3.googleusercontent.com/-1z7oHX9PeDQ/AAAAAAAAAAI/AAAAAAAAAZA/oAjIoG_UNyM/s64/photo.jpg","userId":"16202345156323134081"}}},"source":["# computing loss\n","\n","output = net(input)\n","target = torch.randn(10)\n","target = target.view(1, -1)\n","criterion = nn.MSELoss()\n","\n","loss = criterion(output, target)\n","print(loss)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["tensor(0.5314, grad_fn=<MseLossBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aXwvBrgfNJnG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"0e07ee06-029d-467e-df4a-338fe7edb7b6","executionInfo":{"status":"ok","timestamp":1565603448263,"user_tz":-330,"elapsed":13793,"user":{"displayName":"SANKET RAI","photoUrl":"https://lh3.googleusercontent.com/-1z7oHX9PeDQ/AAAAAAAAAAI/AAAAAAAAAZA/oAjIoG_UNyM/s64/photo.jpg","userId":"16202345156323134081"}}},"source":["print(loss.grad_fn) # MSE loss\n","print(loss.grad_fn.next_functions[0][0]) # Linear\n","print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU"],"execution_count":31,"outputs":[{"output_type":"stream","text":["<MseLossBackward object at 0x7f10b621e710>\n","<AddmmBackward object at 0x7f10b6215cf8>\n","<AccumulateGrad object at 0x7f10b6215f98>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BxC4MenhOhFU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"ad9dfa09-d7a4-4fb0-e12f-9c8b1534eb7e","executionInfo":{"status":"ok","timestamp":1565603767915,"user_tz":-330,"elapsed":888,"user":{"displayName":"SANKET RAI","photoUrl":"https://lh3.googleusercontent.com/-1z7oHX9PeDQ/AAAAAAAAAAI/AAAAAAAAAZA/oAjIoG_UNyM/s64/photo.jpg","userId":"16202345156323134081"}}},"source":["# Backprop\n","\n","# loss.backward() will automatically implement backpropagation\n","\n","# First we need to clear the existing gradients, else new gradients will accumuate to the existing gradients\n","\n","net.zero_grad() # clears all the gradient buffers\n","\n","print('conv1.bias.grad before backprop')\n","print(net.conv1.bias.grad)\n","\n","loss.backward()\n","\n","print('conv1.bias.grad afrer backprop')\n","print(net.conv1.bias.grad)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["conv1.bias.grad before backprop\n","tensor([0., 0., 0., 0., 0., 0.])\n","conv1.bias.grad afrer backprop\n","tensor([-0.0050,  0.0081,  0.0047,  0.0084,  0.0078, -0.0180])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eeqAz69PQaJ4","colab_type":"code","colab":{}},"source":["# weight update\n","\n","import torch.optim as optim\n","\n","optimizer = optim.SGD(net.parameters(), lr=0.01)\n","\n","# include the further section in the training loop\n","\n","optimizer.zero_grad() # zero the gradient buffers\n","output = net(input)\n","loss = criterion(output, target)\n","loss.backward()\n","optimizer.step() # does the weight update"],"execution_count":0,"outputs":[]}]}